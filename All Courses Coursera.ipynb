{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Get all courses",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jh0j1APW-bR"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqrUFSZNex6i"
      },
      "source": [
        "# To get Specializations in Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAPii3fPSljL",
        "outputId": "37f13b8d-3f58-4928-d12f-78e19736d33a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#For Specialization\n",
        "spl_title=[]\n",
        "spl_link=[]\n",
        "\n",
        "import timeit\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "for i in range(1,16):\n",
        "    #44&index=prod_all_products_term_optimization_v3&entityTypeDescription=Specializations&allLanguages=English\n",
        "    url = \"https://www.coursera.org/directory/specializations?page=\" +str(i)\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    st = soup.find_all('a', class_ =\"c-directory-link\")\n",
        "    num=len(st)\n",
        "    for j in range(1,num):\n",
        "        #spl-title\n",
        "        st = soup.find_all('a', class_ =\"c-directory-link\")[j].get_text()\n",
        "        spl_title.append(st)       \n",
        "        #spl URL\n",
        "        curl= soup.find_all(\"a\", class_='c-directory-link')[j]\n",
        "        spl_link.append(\"https://www.coursera.org\"+ curl.get('href'))\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "#creating a dataframe of all specializations\n",
        "splz=pd.DataFrame({'spl_title':spl_title,\n",
        "                   'spl_link':spl_link})\n",
        "\n",
        "\n",
        "#writing into a .csv file\n",
        "#coursera_df.to_csv('Coursera_catalog.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 26.182609796524048s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot4AY_q_fB28"
      },
      "source": [
        "# To get courses in Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OscX1URmVySd"
      },
      "source": [
        "#get all courses on coursera\n",
        "course_title=[]\n",
        "course_link=[]\n",
        "\n",
        "cnt=0\n",
        "for i in range(1,153):\n",
        "    #44&index=prod_all_products_term_optimization_v3&entityTypeDescription=Specializations&allLanguages=English\n",
        "    url = \"https://www.coursera.org/directory/courses?page=\" +str(i)\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    st = soup.find_all('a', class_ =\"c-directory-link\")\n",
        "    num=len(st)\n",
        "    for j in range(1,num):\n",
        "        #course-title\n",
        "        ct = soup.find_all('a', class_ =\"c-directory-link\")[j].get_text()\n",
        "        cnt=cnt+1\n",
        "        course_title.append(ct)       \n",
        "        #course URL\n",
        "        curl= soup.find_all(\"a\", class_='c-directory-link')[j]\n",
        "        course_link.append(\"https://www.coursera.org\"+ curl.get('href'))\n",
        "\n",
        "#creating a dataframe of all specializations\n",
        "courses=pd.DataFrame({'course_title':course_title,\n",
        "                   'course_link':course_link})\n",
        "\n",
        "#writing into a .csv file\n",
        "#coursera_df.to_csv('Coursera_catalog.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7SszB-bfO_j"
      },
      "source": [
        "# To Get Course Details of each Course"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsGeoprrW-dA"
      },
      "source": [
        "#To get detail of each course\n",
        "\n",
        "course_name=[]\n",
        "course_type=[]\n",
        "course_photo_URL=[]\n",
        "typ=[]\n",
        "typ_name=[]\n",
        "university_name=[]\n",
        "university_logo=[]\n",
        "course_link=[]\n",
        "spl_skills=[]\n",
        "course_tit=[]\n",
        "time_required=[]\n",
        "level=[]\n",
        "course_language=[]\n",
        "course_subtitles=[]\n",
        "course_skills=[]\n",
        "category=[]\n",
        "sub_category=[]\n",
        "start = time.time()\n",
        "for urlC,pg in zip(courses.course_link[0:2500],courses.index[0:2500]):\n",
        "    page_course = requests.get(urlC)\n",
        "    soup = BeautifulSoup(page_course.content, 'html.parser')\n",
        "    \n",
        "    guided=soup.find('div',class_=\"_fc5ifbq _bv93ce\")\n",
        "    \n",
        "    if guided is None:\n",
        "      #Attaching course Name/Title\n",
        "      cnn=soup.find('h1',class_=\"banner-title m-b-0 banner-title-without--subtitle\")\n",
        "      if cnn is None:\n",
        "        continue\n",
        "      else:\n",
        "        cnn=cnn.get_text()\n",
        "        course_name.append(cnn)\n",
        "\n",
        "\n",
        "      \n",
        "      #Attaching Course Link\n",
        "      course_link.append(urlC)\n",
        "      #Attaching type of course\n",
        "      typ.append('COURSE')\n",
        "      \n",
        "      #attaching University /name\n",
        "      univ = soup.find('h4', class_ = 'headline-4-text bold rc-Partner__title').get_text()\n",
        "      university_name.append(univ)\n",
        "\n",
        "      #attaching University photo\n",
        "      try:\n",
        "\n",
        "        u_logo=soup.find('div',class_='rc-Partner')\n",
        "        l=u_logo.find('img').get('src')\n",
        "        university_logo.append(l)\n",
        "      except:\n",
        "        university_logo.append(\"not-mentioned\")\n",
        "      \n",
        "      #attaching time required to complete the course\n",
        "      try:\n",
        "\n",
        "        fet=soup.find_all('div',class_='_16ni8zai m-b-0 m-t-1s')\n",
        "      \n",
        "        com=''\n",
        "        for i in fet:\n",
        "          if i is None:\n",
        "            continue\n",
        "          elif \"complete\" in i.get_text():\n",
        "            com=i.get_text()\n",
        "            time_required.append(com)\n",
        "            break\n",
        "          else:\n",
        "            continue\n",
        "  \n",
        "        if com is '':\n",
        "          time_required.append(\"not-mentioned\")\n",
        "      except:\n",
        "        time_required.append(\"not-mentioned\")\n",
        "  \n",
        "      #Attaching Course Languages and course subtitles\n",
        "      try:\n",
        "\n",
        "        \n",
        "        lang=soup.find_all(\"div\",class_=\"_y1d9czk m-b-2 p-t-1s\")[-1]\n",
        "        lgg= lang.find(\"div\",class_=\"_16ni8zai m-b-0\").get_text()\n",
        "        subtitless=lang.find(\"div\",class_=\"content-inner\").get_text()\n",
        "        course_language.append(lgg)\n",
        "        course_subtitles.append(subtitless)\n",
        "      except:\n",
        "        course_language.append(\"not-mentioned\")\n",
        "        course_subtitles.append(\"not-mentioned\")\n",
        "\n",
        "      #Attachng course skills\n",
        "      try:\n",
        "\n",
        "        skills= [x.get_text() for x in soup.find_all('span', class_ = '_rsc0bd m-r-1s m-b-1s')]\n",
        "        course_skills.append(skills)\n",
        "        skills=[]\n",
        "      except:\n",
        "        course_skills.append(\"not-mentioned\")\n",
        "         \n",
        "\n",
        "      #attaching Course Category and sub-category\n",
        "      try:\n",
        "        subj = soup.find_all('a',class_ = '_172v19u6 color-white font-weight-bold')\n",
        "        category.append(subj[1].get_text())\n",
        "        sub_category.append(subj[2].get_text())\n",
        "      except IndexError:\n",
        "        category.append(\"not-mentioned\")\n",
        "        sub_category.append(\"not-mentioned\")\n",
        "      print(pg)\n",
        "    else:\n",
        "      #Attaching Course Link\n",
        "      course_link.append(urlC)\n",
        "      #Attaching course Name/Title\n",
        "      cnn=soup.find('h1',class_=\"_125g251l _gkjc69\").get_text()\n",
        "      course_name.append(cnn)\n",
        "      #Attaching type of course\n",
        "      typ.append('GUIDED PROJECT')\n",
        "      \n",
        "      #attaching University /name\n",
        "      university_name.append('Coursera Project Network')\n",
        "\n",
        "      #attaching University photo\n",
        "      u_logo=soup.find('div',class_='_1tu07i3a')\n",
        "      l=u_logo.find('img').get('src')\n",
        "      university_logo.append(l)\n",
        "      #Attaching course level(Beginner/Intermediate/ Advanced) and  time required to complete\n",
        "      try:\n",
        "        lang=soup.find_all(\"div\",class_=\"_8m7gipb _1f096on\")[1]\n",
        "        lgg= lang.find(\"span\").get_text()\n",
        "      \n",
        "        level.append(lgg)\n",
        "      \n",
        "      #time required to complete the course\n",
        "        vtim=soup.find('span',class_='_1rcyblj').get_text()\n",
        "        time_required.append(vtim)\n",
        "      #Attaching Course Languages and course subtitles\n",
        "        lang=soup.find_all(\"span\",class_=\"_1rcyblj\")[-2].get_text()\n",
        "        course_language.append(lang)\n",
        "        course_subtitles.append(lang)\n",
        "\n",
        "      except:\n",
        "        level.append(\"mixed/not-mentioned\")\n",
        "        time_required.append(\"not-mentioned\")\n",
        "        course_language.append(\"not-mentioned\")\n",
        "        course_subtitles.append(\"not-mentioned\")\n",
        "\n",
        "\n",
        "      #Attachng course skills\n",
        "      try:\n",
        "        skills= [x.get_text() for x in soup.find_all('span', class_ = '_1q9sh65')]\n",
        "        course_skills.append(skills)\n",
        "        skills=[]\n",
        "      except:\n",
        "        course_skills.append(\"not-mentioned\")\n",
        "        \n",
        "\n",
        "      #attaching Course Category and sub-category\n",
        "      try:\n",
        "\n",
        "        subj = soup.find_all('a',class_ = '_k8ap7s6')\n",
        "        category.append(subj[1].get_text())\n",
        "        sub_category.append(subj[2].get_text())\n",
        "      except IndexError:       \n",
        "        category.append(\"not-mentioned\")\n",
        "        sub_category.append(\"not-mentioned\")\n",
        "      print(pg)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalQeYRDfsDS"
      },
      "source": [
        "#Attaching all extracted Course Details to Dataframe:\n",
        " Coursera_courses_catalog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ldTjF6sfjxE"
      },
      "source": [
        "Coursera_courses_catalog=pd.DataFrame({'course_name':course_name,\n",
        "                              'course_link':course_link,\n",
        "                              'university_name':university_name,\n",
        "                              'course_type':typ,\n",
        "                              'university_logo':university_logo,\n",
        "                              'time_required':time_required,\n",
        "                              'course_language':course_language,\n",
        "                              'course_subtitles':course_subtitles,\n",
        "                              'course_skills':course_skills,\n",
        "                              'category':category,\n",
        "                              'sub_category':sub_category})\n",
        "                              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcXWr3lydNna"
      },
      "source": [
        "Coursera_courses_catalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3S5_nvxdPgI"
      },
      "source": [
        "#writing into a .csv file\n",
        "Coursera_courses_catalog.to_csv('Coursera_courses_catalog.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}